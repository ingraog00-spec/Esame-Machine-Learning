# ğŸ©¸ Skin Lesion Classification

Questo progetto affronta la classificazione di immagini dermatoscopiche di lesioni cutanee mediante due approcci distinti:  
1. Una pipeline **Deep Learning** basata su Autoencoder Convoluzionale.
2. Una pipeline **XGBoost** che utilizza feature estratte da un **Vision Transformer (ViT)** pre-addestrato.

Il tracciamento degli esperimenti Ã¨ gestito tramite [Comet ML](https://www.comet.com/). Il progetto Ã¨ sviluppato in PyTorch e scikit-learn.

| | |
| --- | --- |
| **Progetto** | Skin lesion classification using Deep Learning and XGBoost |
| **Autore** | Giovanni Giuseppe Iacuzzo |
| **Corso** | [Machine Learning](https://unikore.it) |

---

## ğŸ“Œ Indice

- [Introduzione](#introduzione)
- [Requisiti](#requisiti)
- [Struttura del Codice](#struttura-del-Codice)
- [Utilizzo](#utilizzo)
- [Confronto tra i modelli](#confronto-tra-i-modelli)

---

## ğŸ§  Introduzione

Il progetto ha l'obiettivo di classificare le lesioni cutanee in base alle immagini. Sono stati implementati e confrontati due approcci:

### 1. Pipeline Deep Learning
- Addestramento di un **Autoencoder Convoluzionale** per l'estrazione non supervisionata di embedding.
- Un **Classificatore Feedforward** viene addestrato sugli embedding per la classificazione.

### 2. Pipeline XGBoost
- Estrazione delle feature dalle immagini usando un **Vision Transformer (ViT)** pre-addestrato.
- Le feature vengono utilizzate per addestrare un **classificatore XGBoost**, con ottimizzazione iperparametrica tramite **GridSearchCV**.

Entrambi gli approcci sono valutati su dataset suddiviso in modo stratificato (train, validation, test).

---

## ğŸ“¦ Requisiti

Il progetto richiede **Python 3.11+**. Le principali librerie utilizzate includono:

- `torch`, `torchvision` â€” per la rete neurale
- `transformers` â€” per lâ€™estrazione feature con ViT
- `scikit-learn`, `xgboost` â€” per classificazione classica ed evaluation
- `matplotlib`, `seaborn` â€” per la visualizzazione
- `comet_ml` â€” per il tracciamento degli esperimenti
- `PyYAML`, `tqdm`, `joblib`, `PIL` â€” utilitÃ  varie

Per installare i requisiti:

```bash
pip install -r requirements.txt
```
---

## ğŸ“  Struttura del Codice

```bash
Esame-Machine-Learning/
â”‚
â”œâ”€â”€ dataset/
â”‚   â””â”€â”€ dataset.py                  # Caricamento e suddivisione del dataset
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ models_autoencoder.py       # Architettura autoencoder
â”‚   â””â”€â”€ model_classifier.py         # Classificatore feedforward
â”‚
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ utils.py                    # Utility e visualizzazioni
â”‚   â”œâ”€â”€ loss.py                     # Loss per il modello di autoencoder
â”‚   â”œâ”€â”€ train_autoencoder.py        # Addestramento autoencoder
â”‚   â”œâ”€â”€ train_classifier.py         # Addestramento classificatore
â”‚   â”œâ”€â”€ feature_extraction.py       # Estrazione embedding dallâ€™autoencoder
â”‚   â””â”€â”€ test.py                     # Script di valutazione
â”‚
â”œâ”€â”€ vision_embeddings.py            # Estrazione embedding da ViT
â”œâ”€â”€ extract_features.py             # Estrazione feature da immagini con ViT
â”‚
â”œâ”€â”€ main_neural_net.py              # Pipeline completa per DL
â”œâ”€â”€ main_XGB_classifier.py          # Pipeline XGBoost
â”‚
â”œâ”€â”€ save_model_autoencoder/         # Cartella Modello autoencoder
â”œâ”€â”€ save_model_embeddings/          # Cartella Modello embeddings
â”œâ”€â”€ save_model_classifier/          # Cartella Modello classifier
â”œâ”€â”€ reconstructions/                # Cartella delle ricostruzioni
â”œâ”€â”€ images/                         # Cartella dove salvare immagini varie
â”‚   â”œâ”€â”€ images/latent_space/        # Cartella rappresentazioni latenti tra le epoche    
â”‚
â”œâ”€â”€ config.yml                      # Configurazione parametri
â”œâ”€â”€ requirements.txt                # Librerie da scaricare
â”œâ”€â”€ .comet.config                   # Config per Comet ML
â”‚
â””â”€â”€ README.md
```
---

## âš™ï¸ Utilizzo
ricordare di eseguire prima il file di preparazione.

- Mac:
```bash
prepare.sh
```

- Windows:
```bash
prepare.bat
```

Per eseguire l'intera pipeline basata su rete neurale (autoencoder + classificatore):

```bash
python main_neural_net.py
```

Esecuzione pipeline XGBoost

- Estrazione feature da immagini con Vision Transformer:
```bash
python extract_features.py
```

- Addestramento e valutazione XGBoost:
```bash
python main_XGB_classifier.py
```
---
## ğŸ”„ Confronto tra i Modelli

Per valutare l'efficacia di diversi approcci nella classificazione delle lesioni cutanee, sono stati implementati e confrontati due modelli distinti:

---

### ğŸ“˜ Approccio 1 â€” Autoencoder + Classificatore Neurale

Questo approccio utilizza un **Autoencoder Convoluzionale** per apprendere rappresentazioni latenti (embedding) delle immagini, seguito da un **classificatore fully-connected** addestrato su tali embedding.

- **Caratteristiche**:
  - Lâ€™autoencoder Ã¨ addestrato in modo non supervisionato sui dati del dataset, il che permette di ottenere feature apprese direttamente dalle immagini delle lesioni.
  - Il classificatore opera nello spazio latente, cercando di distinguere le classi a partire da rappresentazioni compresse ma informative.

- **Obiettivo**:
  - Sfruttare la capacitÃ  dellâ€™autoencoder di estrarre feature significative legate al dominio medico, con una pipeline interamente progettata e addestrata ad hoc.

---

### ğŸ¤– Approccio 2 â€” Vision Transformer + XGBoost

Il secondo modello sfrutta **ViT (Vision Transformer)** pre-addestrato su ImageNet per lâ€™estrazione di embedding visivi, seguiti da un classificatore **XGBoost**, ottimizzato tramite (`GridSearchCV`).

- **Caratteristiche**:
  - Il Vision Transformer fornisce rappresentazioni ad alto livello giÃ  apprese da un modello generalista e potente.
  - XGBoost, noto per la sua robustezza e interpretabilitÃ , viene addestrato sulle feature estratte per eseguire la classificazione.

- **Obiettivo**:
  - Valutare la performance di un approccio ibrido che combina modelli pre-addestrati di visione artificiale con tecniche di apprendimento supervisionato classiche.

---

### ğŸ“Š Riepilogo

| Caratteristica                 | Autoencoder + NN                     | ViT + XGBoost                             |
|-------------------------------|--------------------------------------|-------------------------------------------|
| Estrazione delle feature      | Autoencoder convoluzionale           | Vision Transformer (`google/vit-base`)    |
| Classificatore                | Rete neurale fully-connected         | XGBoost (con GridSearchCV)                |
| Tipo di feature               | Apprese dai dati del dataset         | Pre-addestrate su ImageNet                |
| ComplessitÃ  di addestramento | Medio-alta                           | Bassa (solo XGBoost viene addestrato)     |
| FlessibilitÃ                   | Alta: pipeline personalizzabile      | Media: feature extractor fisso            |
| InterpretabilitÃ               | Limitata                             | Alta (importanza delle feature)           |

---

## ğŸ“ Licenza

Questo progetto Ã¨ distribuito sotto licenza 
[Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International](https://creativecommons.org/licenses/by-nc-nd/4.0/).

[![License: CC BY-NC-ND 4.0](https://img.shields.io/badge/License-CC_BY--NC--ND_4.0-lightgrey.svg)](https://creativecommons.org/licenses/by-nc-nd/4.0/)

---

### ğŸ“© Contatti
Per domande: [giovanni.iacuzzo@unikorestudent.it](mailto:giovanni.iacuzzo@unikorestudent.it)
